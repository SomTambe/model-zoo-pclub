{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ea128da8ab4f4feda8710679eb01be10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a11406a7847d4fa7a710aa9424b33aa6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aa0357845d59479aa4f00b318867b5e3",
              "IPY_MODEL_a8a10613f2824bf1b4482dfe57f62100"
            ]
          }
        },
        "a11406a7847d4fa7a710aa9424b33aa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa0357845d59479aa4f00b318867b5e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_25ea5a7bbd7147339f90fb3e1a6f2606",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db6ef6258b8a4222a9e1bd0f8595dce6"
          }
        },
        "a8a10613f2824bf1b4482dfe57f62100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b3b2ac81012a48f28b53c4458f46b1af",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 55754833.89it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1989b3390e2e4cb69c02ada4046a7893"
          }
        },
        "25ea5a7bbd7147339f90fb3e1a6f2606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db6ef6258b8a4222a9e1bd0f8595dce6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3b2ac81012a48f28b53c4458f46b1af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1989b3390e2e4cb69c02ada4046a7893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJJSglkUzlXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di2Esm_d0M-0",
        "colab_type": "code",
        "outputId": "bb86c226-ef1f-454b-827b-bfebf5dc9f4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "ea128da8ab4f4feda8710679eb01be10",
            "a11406a7847d4fa7a710aa9424b33aa6",
            "aa0357845d59479aa4f00b318867b5e3",
            "a8a10613f2824bf1b4482dfe57f62100",
            "25ea5a7bbd7147339f90fb3e1a6f2606",
            "db6ef6258b8a4222a9e1bd0f8595dce6",
            "b3b2ac81012a48f28b53c4458f46b1af",
            "1989b3390e2e4cb69c02ada4046a7893"
          ]
        }
      },
      "source": [
        "transform=transforms.Compose([transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "trainset=torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                    download=True, transform=transform)\n",
        "trainloader=torch.utils.data.DataLoader(trainset, batch_size=100,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=5,\n",
        "                                         shuffle=False, num_workers=0)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea128da8ab4f4feda8710679eb01be10",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt4T0GZx2XDc",
        "colab_type": "code",
        "outputId": "56ac24db-1b31-4c92-d5d8-5fcb2f525c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "class resnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(resnet, self).__init__()\n",
        "        self.pad=nn.ZeroPad2d(1)\n",
        "        self.layer1=nn.Conv2d(3,16,(3,3),1,padding=1)\n",
        "        self.bloc11=nn.Conv2d(16,16,(3,3),1,padding=1)\n",
        "        self.bloc12=nn.Conv2d(16,16,(3,3),1,padding=1)\n",
        "        self.bloc13=nn.Conv2d(16,16,(3,3),1,padding=1)\n",
        "        self.bloc14=nn.Conv2d(16,16,(3,3),1,padding=1)\n",
        "        self.bloc15=nn.Conv2d(16,16,(3,3),1,padding=1)\n",
        "        self.bloc16=nn.Conv2d(16,16,(3,3),1,padding=1)\n",
        "        self.bloc17=nn.Conv2d(16,16,(3,3),1,padding=1)\n",
        "        self.bloc18=nn.Conv2d(16,16,(3,3),1,padding=1)\n",
        "        self.bloc19=nn.Conv2d(16,16,(3,3),1,padding=1)\n",
        "        self.bloc110=nn.Conv2d(16,16,(3,3),1,padding=1)\n",
        "        self.bn1=nn.BatchNorm2d(16)\n",
        "        self.bn11=nn.BatchNorm2d(16)\n",
        "        self.bn12=nn.BatchNorm2d(16)\n",
        "        self.bn13=nn.BatchNorm2d(16)\n",
        "        self.bn14=nn.BatchNorm2d(16)\n",
        "        self.bn15=nn.BatchNorm2d(16)\n",
        "        self.bn16=nn.BatchNorm2d(16)\n",
        "        self.bn17=nn.BatchNorm2d(16)\n",
        "        self.bn18=nn.BatchNorm2d(16)\n",
        "        self.bn19=nn.BatchNorm2d(16)\n",
        "        self.bn110=nn.BatchNorm2d(16)\n",
        "        self.down1=nn.Conv2d(16,32,(2,2),2)\n",
        "        self.bloc21=nn.Conv2d(32,32,(3,3),1,padding=1)\n",
        "        self.bloc22=nn.Conv2d(32,32,(3,3),1,padding=1)\n",
        "        self.bloc23=nn.Conv2d(32,32,(3,3),1,padding=1)\n",
        "        self.bloc24=nn.Conv2d(32,32,(3,3),1,padding=1)\n",
        "        self.bloc25=nn.Conv2d(32,32,(3,3),1,padding=1)\n",
        "        self.bloc26=nn.Conv2d(32,32,(3,3),1,padding=1)\n",
        "        self.bloc27=nn.Conv2d(32,32,(3,3),1,padding=1)\n",
        "        self.bloc28=nn.Conv2d(32,32,(3,3),1,padding=1)\n",
        "        self.bloc29=nn.Conv2d(32,32,(3,3),1,padding=1)\n",
        "        self.bloc210=nn.Conv2d(32,32,(3,3),1,padding=1)\n",
        "        self.bn2=nn.BatchNorm2d(32)\n",
        "        self.bn21=nn.BatchNorm2d(32)\n",
        "        self.bn22=nn.BatchNorm2d(32)\n",
        "        self.bn23=nn.BatchNorm2d(32)\n",
        "        self.bn24=nn.BatchNorm2d(32)\n",
        "        self.bn25=nn.BatchNorm2d(32)\n",
        "        self.bn26=nn.BatchNorm2d(32)\n",
        "        self.bn27=nn.BatchNorm2d(32)\n",
        "        self.bn28=nn.BatchNorm2d(32)\n",
        "        self.bn29=nn.BatchNorm2d(32)\n",
        "        self.bn210=nn.BatchNorm2d(32)\n",
        "        self.down2=nn.Conv2d(32,64,(2,2),2)\n",
        "        self.bloc31=nn.Conv2d(64,64,(3,3),1,padding=1)\n",
        "        self.bloc32=nn.Conv2d(64,64,(3,3),1,padding=1)\n",
        "        self.bloc33=nn.Conv2d(64,64,(3,3),1,padding=1)\n",
        "        self.bloc34=nn.Conv2d(64,64,(3,3),1,padding=1)\n",
        "        self.bloc35=nn.Conv2d(64,64,(3,3),1,padding=1)\n",
        "        self.bloc36=nn.Conv2d(64,64,(3,3),1,padding=1)\n",
        "        self.bloc37=nn.Conv2d(64,64,(3,3),1,padding=1)\n",
        "        self.bloc38=nn.Conv2d(64,64,(3,3),1,padding=1)\n",
        "        self.bloc39=nn.Conv2d(64,64,(3,3),1,padding=1)\n",
        "        self.bloc310=nn.Conv2d(64,64,(3,3),1,padding=1)\n",
        "        self.bn3=nn.BatchNorm2d(64)\n",
        "        self.bn31=nn.BatchNorm2d(64)\n",
        "        self.bn32=nn.BatchNorm2d(64)\n",
        "        self.bn33=nn.BatchNorm2d(64)\n",
        "        self.bn34=nn.BatchNorm2d(64)\n",
        "        self.bn35=nn.BatchNorm2d(64)\n",
        "        self.bn36=nn.BatchNorm2d(64)\n",
        "        self.bn37=nn.BatchNorm2d(64)\n",
        "        self.bn38=nn.BatchNorm2d(64)\n",
        "        self.bn39=nn.BatchNorm2d(64)\n",
        "        self.bn310=nn.BatchNorm2d(64)\n",
        "        self.avgpool=nn.AdaptiveAvgPool2d((2,2))\n",
        "        # self.fc1=nn.Linear(4096,1024)\n",
        "        self.fc2=nn.Linear(256,10)\n",
        "        # self.softmax=nn.Softmax(0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=F.relu(self.bn1(self.layer1(x)))\n",
        "        # bloc 1 starts here, n=2 => 4 conv layers\n",
        "        t1=x\n",
        "        x=F.relu(self.bn11(self.bloc11(x)))\n",
        "        x=F.relu(self.bn12(self.bloc12(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        t1=x\n",
        "        x=F.relu(self.bn13(self.bloc13(x)))\n",
        "        x=F.relu(self.bn14(self.bloc14(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        t1=x\n",
        "        x=F.relu(self.bn15(self.bloc15(x)))\n",
        "        x=F.relu(self.bn16(self.bloc16(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        t1=x\n",
        "        x=F.relu(self.bn17(self.bloc17(x)))\n",
        "        x=F.relu(self.bn18(self.bloc18(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        t1=x\n",
        "        x=F.relu(self.bn19(self.bloc19(x)))\n",
        "        x=F.relu(self.bn110(self.bloc110(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        # print(x.shape)\n",
        "        # bloc 2\n",
        "        x=self.bn2(self.down1(x))\n",
        "        t1=x\n",
        "        x=F.relu(self.bn21(self.bloc21(x)))\n",
        "        x=F.relu(self.bn22(self.bloc22(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        t1=x\n",
        "        x=F.relu(self.bn23(self.bloc23(x)))\n",
        "        x=F.relu(self.bn24(self.bloc24(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        t1=x\n",
        "        x=F.relu(self.bn25(self.bloc25(x)))\n",
        "        x=F.relu(self.bn26(self.bloc26(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        t1=x\n",
        "        x=F.relu(self.bn27(self.bloc27(x)))\n",
        "        x=F.relu(self.bn28(self.bloc28(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        t1=x\n",
        "        x=F.relu(self.bn29(self.bloc29(x)))\n",
        "        x=F.relu(self.bn210(self.bloc210(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        # print(x.shape)\n",
        "        # bloc 3\n",
        "        x=self.bn3(self.down2(x))\n",
        "        t1=x\n",
        "        x=F.relu(self.bn31(self.bloc31(x)))\n",
        "        x=F.relu(self.bn32(self.bloc32(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        t1=x\n",
        "        x=F.relu(self.bn33(self.bloc33(x)))\n",
        "        x=F.relu(self.bn34(self.bloc34(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        t1=x\n",
        "        x=F.relu(self.bn35(self.bloc35(x)))\n",
        "        x=F.relu(self.bn36(self.bloc36(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        t1=x\n",
        "        x=F.relu(self.bn37(self.bloc37(x)))\n",
        "        x=F.relu(self.bn38(self.bloc38(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        t1=x\n",
        "        x=F.relu(self.bn39(self.bloc39(x)))\n",
        "        x=F.relu(self.bn310(self.bloc310(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        x=self.avgpool(x)\n",
        "        x=x.view(-1,256)\n",
        "        # x=F.relu(self.fc1(x))\n",
        "        # print(x.shape)\n",
        "        # x=self.softmax(self.fc2(x))\n",
        "        x=self.fc2(x)\n",
        "        return x\n",
        "net=resnet()\n",
        "print(summary(resnet().to('cuda:0'),(3,32,32)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             448\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "            Conv2d-3           [-1, 16, 32, 32]           2,320\n",
            "       BatchNorm2d-4           [-1, 16, 32, 32]              32\n",
            "            Conv2d-5           [-1, 16, 32, 32]           2,320\n",
            "       BatchNorm2d-6           [-1, 16, 32, 32]              32\n",
            "            Conv2d-7           [-1, 16, 32, 32]           2,320\n",
            "       BatchNorm2d-8           [-1, 16, 32, 32]              32\n",
            "            Conv2d-9           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-10           [-1, 16, 32, 32]              32\n",
            "           Conv2d-11           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-12           [-1, 16, 32, 32]              32\n",
            "           Conv2d-13           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-14           [-1, 16, 32, 32]              32\n",
            "           Conv2d-15           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-16           [-1, 16, 32, 32]              32\n",
            "           Conv2d-17           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-18           [-1, 16, 32, 32]              32\n",
            "           Conv2d-19           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-20           [-1, 16, 32, 32]              32\n",
            "           Conv2d-21           [-1, 16, 32, 32]           2,320\n",
            "      BatchNorm2d-22           [-1, 16, 32, 32]              32\n",
            "           Conv2d-23           [-1, 32, 16, 16]           2,080\n",
            "      BatchNorm2d-24           [-1, 32, 16, 16]              64\n",
            "           Conv2d-25           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-26           [-1, 32, 16, 16]              64\n",
            "           Conv2d-27           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-28           [-1, 32, 16, 16]              64\n",
            "           Conv2d-29           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-30           [-1, 32, 16, 16]              64\n",
            "           Conv2d-31           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-32           [-1, 32, 16, 16]              64\n",
            "           Conv2d-33           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-34           [-1, 32, 16, 16]              64\n",
            "           Conv2d-35           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-36           [-1, 32, 16, 16]              64\n",
            "           Conv2d-37           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-38           [-1, 32, 16, 16]              64\n",
            "           Conv2d-39           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-40           [-1, 32, 16, 16]              64\n",
            "           Conv2d-41           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-42           [-1, 32, 16, 16]              64\n",
            "           Conv2d-43           [-1, 32, 16, 16]           9,248\n",
            "      BatchNorm2d-44           [-1, 32, 16, 16]              64\n",
            "           Conv2d-45             [-1, 64, 8, 8]           8,256\n",
            "      BatchNorm2d-46             [-1, 64, 8, 8]             128\n",
            "           Conv2d-47             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-48             [-1, 64, 8, 8]             128\n",
            "           Conv2d-49             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-50             [-1, 64, 8, 8]             128\n",
            "           Conv2d-51             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-52             [-1, 64, 8, 8]             128\n",
            "           Conv2d-53             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-54             [-1, 64, 8, 8]             128\n",
            "           Conv2d-55             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-56             [-1, 64, 8, 8]             128\n",
            "           Conv2d-57             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-58             [-1, 64, 8, 8]             128\n",
            "           Conv2d-59             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-60             [-1, 64, 8, 8]             128\n",
            "           Conv2d-61             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-62             [-1, 64, 8, 8]             128\n",
            "           Conv2d-63             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-64             [-1, 64, 8, 8]             128\n",
            "           Conv2d-65             [-1, 64, 8, 8]          36,928\n",
            "      BatchNorm2d-66             [-1, 64, 8, 8]             128\n",
            "AdaptiveAvgPool2d-67             [-1, 64, 2, 2]               0\n",
            "           Linear-68                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 500,778\n",
            "Trainable params: 500,778\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 4.81\n",
            "Params size (MB): 1.91\n",
            "Estimated Total Size (MB): 6.74\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He4_4N4QA7VW",
        "colab_type": "code",
        "outputId": "bcaa3f30-dcdd-4746-fa28-8b4e95b20029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "net.to(device)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(net.parameters())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZnqAg9ABS1O",
        "colab_type": "code",
        "outputId": "9e0a096b-7e01-4af9-dc34-533ae0100993",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(100): # no of epochs\n",
        "    \n",
        "    running_loss=0.0\n",
        "    \n",
        "    net.train()\n",
        "    \n",
        "    for i,data in enumerate(trainloader):\n",
        "          inputs, labels = data[0].to(device), data[1].to(device)\n",
        "          optimizer.zero_grad()\n",
        "          outputs=net(inputs)\n",
        "          loss=criterion(outputs,labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss+=loss.item()\n",
        "\n",
        "    correct_test=0\n",
        "    total_test=0\n",
        "    correct_train=0\n",
        "    total_train=0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs=net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "        for data in trainloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs=net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "    print(correct_test,total_test,correct_train,total_train)\n",
        "    print(\"Epoch=\",epoch+1,\" Train Accuracy=\",correct_train*100/total_train,\", Test Accuracy=\",correct_test*100/total_test, \" Epoch loss=\",running_loss)\n",
        "print('Model trained :)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6023 10000 30468 50000\n",
            "Epoch= 1  Train Accuracy= 60.936 , Test Accuracy= 60.23  Epoch loss= 686.9653576016426\n",
            "7149 10000 37106 50000\n",
            "Epoch= 2  Train Accuracy= 74.212 , Test Accuracy= 71.49  Epoch loss= 425.99579083919525\n",
            "7678 10000 40308 50000\n",
            "Epoch= 3  Train Accuracy= 80.616 , Test Accuracy= 76.78  Epoch loss= 327.24042013287544\n",
            "7717 10000 40850 50000\n",
            "Epoch= 4  Train Accuracy= 81.7 , Test Accuracy= 77.17  Epoch loss= 272.99186542630196\n",
            "7947 10000 42347 50000\n",
            "Epoch= 5  Train Accuracy= 84.694 , Test Accuracy= 79.47  Epoch loss= 230.7350639104843\n",
            "8004 10000 43808 50000\n",
            "Epoch= 6  Train Accuracy= 87.616 , Test Accuracy= 80.04  Epoch loss= 199.38875469565392\n",
            "7890 10000 43195 50000\n",
            "Epoch= 7  Train Accuracy= 86.39 , Test Accuracy= 78.9  Epoch loss= 171.23716513812542\n",
            "8163 10000 45352 50000\n",
            "Epoch= 8  Train Accuracy= 90.704 , Test Accuracy= 81.63  Epoch loss= 151.54967494308949\n",
            "8105 10000 46039 50000\n",
            "Epoch= 9  Train Accuracy= 92.078 , Test Accuracy= 81.05  Epoch loss= 124.64143622666597\n",
            "8284 10000 47146 50000\n",
            "Epoch= 10  Train Accuracy= 94.292 , Test Accuracy= 82.84  Epoch loss= 107.889425188303\n",
            "8250 10000 47525 50000\n",
            "Epoch= 11  Train Accuracy= 95.05 , Test Accuracy= 82.5  Epoch loss= 90.89558223262429\n",
            "8128 10000 46732 50000\n",
            "Epoch= 12  Train Accuracy= 93.464 , Test Accuracy= 81.28  Epoch loss= 74.99460339546204\n",
            "8245 10000 47586 50000\n",
            "Epoch= 13  Train Accuracy= 95.172 , Test Accuracy= 82.45  Epoch loss= 68.23317043855786\n",
            "8253 10000 48163 50000\n",
            "Epoch= 14  Train Accuracy= 96.326 , Test Accuracy= 82.53  Epoch loss= 58.68056268058717\n",
            "8216 10000 47981 50000\n",
            "Epoch= 15  Train Accuracy= 95.962 , Test Accuracy= 82.16  Epoch loss= 50.02655367553234\n",
            "8261 10000 48580 50000\n",
            "Epoch= 16  Train Accuracy= 97.16 , Test Accuracy= 82.61  Epoch loss= 45.37671460490674\n",
            "8144 10000 47620 50000\n",
            "Epoch= 17  Train Accuracy= 95.24 , Test Accuracy= 81.44  Epoch loss= 41.8432340323925\n",
            "8081 10000 47435 50000\n",
            "Epoch= 18  Train Accuracy= 94.87 , Test Accuracy= 80.81  Epoch loss= 39.46374418400228\n",
            "8034 10000 47138 50000\n",
            "Epoch= 19  Train Accuracy= 94.276 , Test Accuracy= 80.34  Epoch loss= 32.111014009453356\n",
            "8270 10000 48496 50000\n",
            "Epoch= 20  Train Accuracy= 96.992 , Test Accuracy= 82.7  Epoch loss= 30.1344786407426\n",
            "8063 10000 47614 50000\n",
            "Epoch= 21  Train Accuracy= 95.228 , Test Accuracy= 80.63  Epoch loss= 32.47026591422036\n",
            "8339 10000 49146 50000\n",
            "Epoch= 22  Train Accuracy= 98.292 , Test Accuracy= 83.39  Epoch loss= 34.85312482248992\n",
            "8074 10000 47535 50000\n",
            "Epoch= 23  Train Accuracy= 95.07 , Test Accuracy= 80.74  Epoch loss= 23.536510869394988\n",
            "8414 10000 49409 50000\n",
            "Epoch= 24  Train Accuracy= 98.818 , Test Accuracy= 84.14  Epoch loss= 28.990423226729035\n",
            "8330 10000 49300 50000\n",
            "Epoch= 25  Train Accuracy= 98.6 , Test Accuracy= 83.3  Epoch loss= 21.75180710409768\n",
            "8041 10000 47798 50000\n",
            "Epoch= 26  Train Accuracy= 95.596 , Test Accuracy= 80.41  Epoch loss= 27.037732887547463\n",
            "8300 10000 48959 50000\n",
            "Epoch= 27  Train Accuracy= 97.918 , Test Accuracy= 83.0  Epoch loss= 23.429138409905136\n",
            "8230 10000 48695 50000\n",
            "Epoch= 28  Train Accuracy= 97.39 , Test Accuracy= 82.3  Epoch loss= 23.354104881407693\n",
            "8230 10000 48894 50000\n",
            "Epoch= 29  Train Accuracy= 97.788 , Test Accuracy= 82.3  Epoch loss= 21.296197549905628\n",
            "8316 10000 49132 50000\n",
            "Epoch= 30  Train Accuracy= 98.264 , Test Accuracy= 83.16  Epoch loss= 20.082405878813006\n",
            "8216 10000 48859 50000\n",
            "Epoch= 31  Train Accuracy= 97.718 , Test Accuracy= 82.16  Epoch loss= 19.361528071574867\n",
            "8338 10000 49431 50000\n",
            "Epoch= 32  Train Accuracy= 98.862 , Test Accuracy= 83.38  Epoch loss= 22.32327079633251\n",
            "8345 10000 49369 50000\n",
            "Epoch= 33  Train Accuracy= 98.738 , Test Accuracy= 83.45  Epoch loss= 17.610991852299776\n",
            "8362 10000 49388 50000\n",
            "Epoch= 34  Train Accuracy= 98.776 , Test Accuracy= 83.62  Epoch loss= 19.99824112211354\n",
            "8387 10000 49419 50000\n",
            "Epoch= 35  Train Accuracy= 98.838 , Test Accuracy= 83.87  Epoch loss= 15.051981503260322\n",
            "8313 10000 49318 50000\n",
            "Epoch= 36  Train Accuracy= 98.636 , Test Accuracy= 83.13  Epoch loss= 15.048337992047891\n",
            "8347 10000 49359 50000\n",
            "Epoch= 37  Train Accuracy= 98.718 , Test Accuracy= 83.47  Epoch loss= 21.164499289239757\n",
            "8371 10000 49472 50000\n",
            "Epoch= 38  Train Accuracy= 98.944 , Test Accuracy= 83.71  Epoch loss= 19.033395014703274\n",
            "8358 10000 49551 50000\n",
            "Epoch= 39  Train Accuracy= 99.102 , Test Accuracy= 83.58  Epoch loss= 9.73127127304906\n",
            "8383 10000 49449 50000\n",
            "Epoch= 40  Train Accuracy= 98.898 , Test Accuracy= 83.83  Epoch loss= 17.584912490448914\n",
            "8443 10000 49690 50000\n",
            "Epoch= 41  Train Accuracy= 99.38 , Test Accuracy= 84.43  Epoch loss= 15.258318025677\n",
            "8426 10000 49686 50000\n",
            "Epoch= 42  Train Accuracy= 99.372 , Test Accuracy= 84.26  Epoch loss= 11.506310994038358\n",
            "8389 10000 49450 50000\n",
            "Epoch= 43  Train Accuracy= 98.9 , Test Accuracy= 83.89  Epoch loss= 16.798135151620954\n",
            "8407 10000 49506 50000\n",
            "Epoch= 44  Train Accuracy= 99.012 , Test Accuracy= 84.07  Epoch loss= 13.219041063537588\n",
            "8380 10000 49546 50000\n",
            "Epoch= 45  Train Accuracy= 99.092 , Test Accuracy= 83.8  Epoch loss= 15.664928694372065\n",
            "8287 10000 49200 50000\n",
            "Epoch= 46  Train Accuracy= 98.4 , Test Accuracy= 82.87  Epoch loss= 13.037113655707799\n",
            "8355 10000 49548 50000\n",
            "Epoch= 47  Train Accuracy= 99.096 , Test Accuracy= 83.55  Epoch loss= 11.120231191685889\n",
            "8310 10000 49400 50000\n",
            "Epoch= 48  Train Accuracy= 98.8 , Test Accuracy= 83.1  Epoch loss= 8.583778194035403\n",
            "8272 10000 49197 50000\n",
            "Epoch= 49  Train Accuracy= 98.394 , Test Accuracy= 82.72  Epoch loss= 14.404557341040345\n",
            "8437 10000 49727 50000\n",
            "Epoch= 50  Train Accuracy= 99.454 , Test Accuracy= 84.37  Epoch loss= 15.888108800252667\n",
            "8395 10000 49720 50000\n",
            "Epoch= 51  Train Accuracy= 99.44 , Test Accuracy= 83.95  Epoch loss= 10.571073012659326\n",
            "8366 10000 49721 50000\n",
            "Epoch= 52  Train Accuracy= 99.442 , Test Accuracy= 83.66  Epoch loss= 7.333909645152744\n",
            "8393 10000 49633 50000\n",
            "Epoch= 53  Train Accuracy= 99.266 , Test Accuracy= 83.93  Epoch loss= 14.072036858357023\n",
            "8386 10000 49606 50000\n",
            "Epoch= 54  Train Accuracy= 99.212 , Test Accuracy= 83.86  Epoch loss= 13.099259973154403\n",
            "8395 10000 49689 50000\n",
            "Epoch= 55  Train Accuracy= 99.378 , Test Accuracy= 83.95  Epoch loss= 8.76291266066255\n",
            "8372 10000 49664 50000\n",
            "Epoch= 56  Train Accuracy= 99.328 , Test Accuracy= 83.72  Epoch loss= 7.748664876125986\n",
            "8306 10000 49455 50000\n",
            "Epoch= 57  Train Accuracy= 98.91 , Test Accuracy= 83.06  Epoch loss= 17.20758267684141\n",
            "8424 10000 49792 50000\n",
            "Epoch= 58  Train Accuracy= 99.584 , Test Accuracy= 84.24  Epoch loss= 10.109633486077655\n",
            "8394 10000 49658 50000\n",
            "Epoch= 59  Train Accuracy= 99.316 , Test Accuracy= 83.94  Epoch loss= 7.6078770262538455\n",
            "8282 10000 49196 50000\n",
            "Epoch= 60  Train Accuracy= 98.392 , Test Accuracy= 82.82  Epoch loss= 10.755757914594142\n",
            "8364 10000 49597 50000\n",
            "Epoch= 61  Train Accuracy= 99.194 , Test Accuracy= 83.64  Epoch loss= 8.444233432644978\n",
            "8339 10000 49623 50000\n",
            "Epoch= 62  Train Accuracy= 99.246 , Test Accuracy= 83.39  Epoch loss= 12.131993041781243\n",
            "8414 10000 49715 50000\n",
            "Epoch= 63  Train Accuracy= 99.43 , Test Accuracy= 84.14  Epoch loss= 8.518174554686993\n",
            "8412 10000 49782 50000\n",
            "Epoch= 64  Train Accuracy= 99.564 , Test Accuracy= 84.12  Epoch loss= 8.21498124790378\n",
            "8394 10000 49705 50000\n",
            "Epoch= 65  Train Accuracy= 99.41 , Test Accuracy= 83.94  Epoch loss= 11.04325389789301\n",
            "8426 10000 49853 50000\n",
            "Epoch= 66  Train Accuracy= 99.706 , Test Accuracy= 84.26  Epoch loss= 7.369457968889037\n",
            "8234 10000 49216 50000\n",
            "Epoch= 67  Train Accuracy= 98.432 , Test Accuracy= 82.34  Epoch loss= 7.511208726209588\n",
            "8379 10000 49612 50000\n",
            "Epoch= 68  Train Accuracy= 99.224 , Test Accuracy= 83.79  Epoch loss= 11.395366422599182\n",
            "8225 10000 49246 50000\n",
            "Epoch= 69  Train Accuracy= 98.492 , Test Accuracy= 82.25  Epoch loss= 9.971065289573744\n",
            "8397 10000 49820 50000\n",
            "Epoch= 70  Train Accuracy= 99.64 , Test Accuracy= 83.97  Epoch loss= 9.000412990193581\n",
            "8412 10000 49803 50000\n",
            "Epoch= 71  Train Accuracy= 99.606 , Test Accuracy= 84.12  Epoch loss= 5.4864202563258\n",
            "8334 10000 49428 50000\n",
            "Epoch= 72  Train Accuracy= 98.856 , Test Accuracy= 83.34  Epoch loss= 9.520118581684073\n",
            "8478 10000 49914 50000\n",
            "Epoch= 73  Train Accuracy= 99.828 , Test Accuracy= 84.78  Epoch loss= 13.585023363964865\n",
            "8432 10000 49870 50000\n",
            "Epoch= 74  Train Accuracy= 99.74 , Test Accuracy= 84.32  Epoch loss= 5.338940350717166\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-72b7358481f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mtotal_test\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mcorrect_test\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yifB_L3atvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0a9eacf3-0a4d-4f85-d7f3-49835360ed2c"
      },
      "source": [
        " class resnet2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(resnet2, self).__init__()\n",
        "        self.pad=nn.ZeroPad2d(1)\n",
        "        self.layer1=nn.Conv2d(3,16,(3,3),1,padding=1)\n",
        "        self.bloc11=nn.Conv2d(16,8,(1,1),1)\n",
        "        self.bloc12=nn.Conv2d(8,8,(3,3),1,padding=1)\n",
        "        self.bloc13=nn.Conv2d(8,16,(1,1),1)\n",
        "        self.bloc14=nn.Conv2d(16,8,(1,1),1)\n",
        "        self.bloc15=nn.Conv2d(8,8,(3,3),1,padding=1)\n",
        "        self.bloc16=nn.Conv2d(8,16,(1,1),1)\n",
        "        self.bn1=nn.BatchNorm2d(16)\n",
        "        self.bn11=nn.BatchNorm2d(8)\n",
        "        self.bn12=nn.BatchNorm2d(8)\n",
        "        self.bn13=nn.BatchNorm2d(16)\n",
        "        self.bn14=nn.BatchNorm2d(8)\n",
        "        self.bn15=nn.BatchNorm2d(8)\n",
        "        self.bn16=nn.BatchNorm2d(16)\n",
        "        self.down1=nn.Conv2d(16,32,(2,2),2)\n",
        "        self.bloc21=nn.Conv2d(32,16,(1,1),1)\n",
        "        self.bloc22=nn.Conv2d(16,16,(3,3),1,padding=1)\n",
        "        self.bloc23=nn.Conv2d(16,32,(1,1),1)\n",
        "        self.bloc24=nn.Conv2d(32,16,(1,1),1)\n",
        "        self.bloc25=nn.Conv2d(16,16,(3,3),1,padding=1)\n",
        "        self.bloc26=nn.Conv2d(16,32,(1,1),1)\n",
        "        self.bn2=nn.BatchNorm2d(32)\n",
        "        self.bn21=nn.BatchNorm2d(16)\n",
        "        self.bn22=nn.BatchNorm2d(16)\n",
        "        self.bn23=nn.BatchNorm2d(32)\n",
        "        self.bn24=nn.BatchNorm2d(16)\n",
        "        self.bn25=nn.BatchNorm2d(16)\n",
        "        self.bn26=nn.BatchNorm2d(32)\n",
        "        self.down2=nn.Conv2d(32,64,(2,2),2)\n",
        "        self.bloc31=nn.Conv2d(64,32,(1,1),1)\n",
        "        self.bloc32=nn.Conv2d(32,32,(3,3),1,padding=1)\n",
        "        self.bloc33=nn.Conv2d(32,64,(1,1),1)\n",
        "        self.bloc34=nn.Conv2d(64,32,(1,1),1)\n",
        "        self.bloc35=nn.Conv2d(32,32,(3,3),1,padding=1)\n",
        "        self.bloc36=nn.Conv2d(32,64,(1,1),1)\n",
        "        self.bn3=nn.BatchNorm2d(64)\n",
        "        self.bn31=nn.BatchNorm2d(32)\n",
        "        self.bn32=nn.BatchNorm2d(32)\n",
        "        self.bn33=nn.BatchNorm2d(64)\n",
        "        self.bn34=nn.BatchNorm2d(32)\n",
        "        self.bn35=nn.BatchNorm2d(32)\n",
        "        self.bn36=nn.BatchNorm2d(64)\n",
        "        self.avgpool=nn.AdaptiveAvgPool2d((2,2))\n",
        "        # self.fc1=nn.Linear(4096,1024)\n",
        "        self.fc2=nn.Linear(256,10)\n",
        "        # self.softmax=nn.Softmax(0)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=F.relu(self.bn1(self.layer1(x)))\n",
        "        # bloc 1 starts here, n=2 => 4 conv layers\n",
        "        t1=x\n",
        "        x=F.relu(self.bn11(self.bloc11(x)))\n",
        "        x=F.relu(self.bn12(self.bloc12(x)))\n",
        "        x=F.relu(self.bn13(self.bloc13(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        t1=x\n",
        "        x=F.relu(self.bn14(self.bloc14(x)))\n",
        "        x=F.relu(self.bn15(self.bloc15(x)))\n",
        "        x=F.relu(self.bn16(self.bloc16(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        # print(x.shape)\n",
        "        # bloc 2\n",
        "        x=self.bn2(self.down1(x))\n",
        "        t1=x\n",
        "        x=F.relu(self.bn21(self.bloc21(x)))\n",
        "        x=F.relu(self.bn22(self.bloc22(x)))\n",
        "        x=F.relu(self.bn23(self.bloc23(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        t1=x\n",
        "        x=F.relu(self.bn24(self.bloc24(x)))\n",
        "        x=F.relu(self.bn25(self.bloc25(x)))\n",
        "        x=F.relu(self.bn26(self.bloc26(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        # print(x.shape)\n",
        "        # bloc 3\n",
        "        x=self.bn3(self.down2(x))\n",
        "        t1=x\n",
        "        x=F.relu(self.bn31(self.bloc31(x)))\n",
        "        x=F.relu(self.bn32(self.bloc32(x)))\n",
        "        x=F.relu(self.bn33(self.bloc33(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        t1=x\n",
        "        x=F.relu(self.bn34(self.bloc34(x)))\n",
        "        x=F.relu(self.bn35(self.bloc35(x)))\n",
        "        x=F.relu(self.bn36(self.bloc36(x)))\n",
        "        x=F.relu(t1+x)\n",
        "        x=self.avgpool(x)\n",
        "        x=x.view(-1,256)\n",
        "        # x=F.relu(self.fc1(x))\n",
        "        # print(x.shape)\n",
        "        # x=self.softmax(self.fc2(x))\n",
        "        x=self.fc2(x)\n",
        "        return x\n",
        "net2=resnet2()\n",
        "print(summary(resnet2().to('cuda:0'),(3,32,32)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             448\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "            Conv2d-3            [-1, 8, 32, 32]             136\n",
            "       BatchNorm2d-4            [-1, 8, 32, 32]              16\n",
            "            Conv2d-5            [-1, 8, 32, 32]             584\n",
            "       BatchNorm2d-6            [-1, 8, 32, 32]              16\n",
            "            Conv2d-7           [-1, 16, 32, 32]             144\n",
            "       BatchNorm2d-8           [-1, 16, 32, 32]              32\n",
            "            Conv2d-9            [-1, 8, 32, 32]             136\n",
            "      BatchNorm2d-10            [-1, 8, 32, 32]              16\n",
            "           Conv2d-11            [-1, 8, 32, 32]             584\n",
            "      BatchNorm2d-12            [-1, 8, 32, 32]              16\n",
            "           Conv2d-13           [-1, 16, 32, 32]             144\n",
            "      BatchNorm2d-14           [-1, 16, 32, 32]              32\n",
            "           Conv2d-15           [-1, 32, 16, 16]           2,080\n",
            "      BatchNorm2d-16           [-1, 32, 16, 16]              64\n",
            "           Conv2d-17           [-1, 16, 16, 16]             528\n",
            "      BatchNorm2d-18           [-1, 16, 16, 16]              32\n",
            "           Conv2d-19           [-1, 16, 16, 16]           2,320\n",
            "      BatchNorm2d-20           [-1, 16, 16, 16]              32\n",
            "           Conv2d-21           [-1, 32, 16, 16]             544\n",
            "      BatchNorm2d-22           [-1, 32, 16, 16]              64\n",
            "           Conv2d-23           [-1, 16, 16, 16]             528\n",
            "      BatchNorm2d-24           [-1, 16, 16, 16]              32\n",
            "           Conv2d-25           [-1, 16, 16, 16]           2,320\n",
            "      BatchNorm2d-26           [-1, 16, 16, 16]              32\n",
            "           Conv2d-27           [-1, 32, 16, 16]             544\n",
            "      BatchNorm2d-28           [-1, 32, 16, 16]              64\n",
            "           Conv2d-29             [-1, 64, 8, 8]           8,256\n",
            "      BatchNorm2d-30             [-1, 64, 8, 8]             128\n",
            "           Conv2d-31             [-1, 32, 8, 8]           2,080\n",
            "      BatchNorm2d-32             [-1, 32, 8, 8]              64\n",
            "           Conv2d-33             [-1, 32, 8, 8]           9,248\n",
            "      BatchNorm2d-34             [-1, 32, 8, 8]              64\n",
            "           Conv2d-35             [-1, 64, 8, 8]           2,112\n",
            "      BatchNorm2d-36             [-1, 64, 8, 8]             128\n",
            "           Conv2d-37             [-1, 32, 8, 8]           2,080\n",
            "      BatchNorm2d-38             [-1, 32, 8, 8]              64\n",
            "           Conv2d-39             [-1, 32, 8, 8]           9,248\n",
            "      BatchNorm2d-40             [-1, 32, 8, 8]              64\n",
            "           Conv2d-41             [-1, 64, 8, 8]           2,112\n",
            "      BatchNorm2d-42             [-1, 64, 8, 8]             128\n",
            "AdaptiveAvgPool2d-43             [-1, 64, 2, 2]               0\n",
            "           Linear-44                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 49,866\n",
            "Trainable params: 49,866\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.19\n",
            "Params size (MB): 0.19\n",
            "Estimated Total Size (MB): 2.39\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ2GGWaDH1IM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "661457f5-a8bc-4ccb-b107-89c5b89156f0"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "net2.to(device)\n",
        "criterion2=nn.CrossEntropyLoss()\n",
        "optimizer2=optim.Adam(net2.parameters())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lizdQK4GIjIk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4822a58c-5523-4df9-eeb3-068515113269"
      },
      "source": [
        "for epoch in range(100): # no of epochs\n",
        "    \n",
        "    running_loss=0.0\n",
        "    \n",
        "    net2.train()\n",
        "    \n",
        "    for i,data in enumerate(trainloader):\n",
        "          inputs, labels = data[0].to(device), data[1].to(device)\n",
        "          optimizer2.zero_grad()\n",
        "          outputs=net2(inputs)\n",
        "          loss=criterion2(outputs,labels)\n",
        "          loss.backward()\n",
        "          optimizer2.step()\n",
        "          running_loss+=loss.item()\n",
        "\n",
        "    correct_test=0\n",
        "    total_test=0\n",
        "    correct_train=0\n",
        "    total_train=0\n",
        "    net2.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs=net2(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "        for data in trainloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs=net2(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "    print(correct_test,total_test,correct_train,total_train)\n",
        "    print(\"Epoch=\",epoch+1,\" Train Accuracy=\",correct_train*100/total_train,\", Test Accuracy=\",correct_test*100/total_test, \" Epoch loss=\",running_loss)\n",
        "print('Model trained :)')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6522 10000 33060 50000\n",
            "Epoch= 1  Train Accuracy= 66.12 , Test Accuracy= 65.22  Epoch loss= 525.3035990595818\n",
            "6970 10000 36045 50000\n",
            "Epoch= 2  Train Accuracy= 72.09 , Test Accuracy= 69.7  Epoch loss= 441.6996923685074\n",
            "7060 10000 36657 50000\n",
            "Epoch= 3  Train Accuracy= 73.314 , Test Accuracy= 70.6  Epoch loss= 390.7412217259407\n",
            "7078 10000 37219 50000\n",
            "Epoch= 4  Train Accuracy= 74.438 , Test Accuracy= 70.78  Epoch loss= 359.5159174799919\n",
            "7332 10000 38665 50000\n",
            "Epoch= 5  Train Accuracy= 77.33 , Test Accuracy= 73.32  Epoch loss= 331.99311205744743\n",
            "7418 10000 39768 50000\n",
            "Epoch= 6  Train Accuracy= 79.536 , Test Accuracy= 74.18  Epoch loss= 311.0041953623295\n",
            "7577 10000 40471 50000\n",
            "Epoch= 7  Train Accuracy= 80.942 , Test Accuracy= 75.77  Epoch loss= 290.82076928019524\n",
            "7595 10000 41024 50000\n",
            "Epoch= 8  Train Accuracy= 82.048 , Test Accuracy= 75.95  Epoch loss= 277.41259041428566\n",
            "7552 10000 41372 50000\n",
            "Epoch= 9  Train Accuracy= 82.744 , Test Accuracy= 75.52  Epoch loss= 261.16854628920555\n",
            "7651 10000 41817 50000\n",
            "Epoch= 10  Train Accuracy= 83.634 , Test Accuracy= 76.51  Epoch loss= 250.99608778953552\n",
            "7475 10000 41339 50000\n",
            "Epoch= 11  Train Accuracy= 82.678 , Test Accuracy= 74.75  Epoch loss= 237.70520558953285\n",
            "7695 10000 42593 50000\n",
            "Epoch= 12  Train Accuracy= 85.186 , Test Accuracy= 76.95  Epoch loss= 228.23346631228924\n",
            "7669 10000 43138 50000\n",
            "Epoch= 13  Train Accuracy= 86.276 , Test Accuracy= 76.69  Epoch loss= 217.85178244113922\n",
            "7667 10000 43559 50000\n",
            "Epoch= 14  Train Accuracy= 87.118 , Test Accuracy= 76.67  Epoch loss= 207.64664298295975\n",
            "7460 10000 42466 50000\n",
            "Epoch= 15  Train Accuracy= 84.932 , Test Accuracy= 74.6  Epoch loss= 197.63017717003822\n",
            "7480 10000 43016 50000\n",
            "Epoch= 16  Train Accuracy= 86.032 , Test Accuracy= 74.8  Epoch loss= 189.7727750390768\n",
            "7657 10000 44708 50000\n",
            "Epoch= 17  Train Accuracy= 89.416 , Test Accuracy= 76.57  Epoch loss= 180.86953502893448\n",
            "7746 10000 44574 50000\n",
            "Epoch= 18  Train Accuracy= 89.148 , Test Accuracy= 77.46  Epoch loss= 173.64982457458973\n",
            "7629 10000 44165 50000\n",
            "Epoch= 19  Train Accuracy= 88.33 , Test Accuracy= 76.29  Epoch loss= 164.67407628893852\n",
            "7627 10000 44444 50000\n",
            "Epoch= 20  Train Accuracy= 88.888 , Test Accuracy= 76.27  Epoch loss= 161.48739205300808\n",
            "7621 10000 44944 50000\n",
            "Epoch= 21  Train Accuracy= 89.888 , Test Accuracy= 76.21  Epoch loss= 154.1834266334772\n",
            "7532 10000 44596 50000\n",
            "Epoch= 22  Train Accuracy= 89.192 , Test Accuracy= 75.32  Epoch loss= 146.0356712564826\n",
            "7707 10000 46068 50000\n",
            "Epoch= 23  Train Accuracy= 92.136 , Test Accuracy= 77.07  Epoch loss= 140.08099684119225\n",
            "7541 10000 45141 50000\n",
            "Epoch= 24  Train Accuracy= 90.282 , Test Accuracy= 75.41  Epoch loss= 133.90603835880756\n",
            "7521 10000 45146 50000\n",
            "Epoch= 25  Train Accuracy= 90.292 , Test Accuracy= 75.21  Epoch loss= 134.40040332078934\n",
            "7639 10000 46364 50000\n",
            "Epoch= 26  Train Accuracy= 92.728 , Test Accuracy= 76.39  Epoch loss= 125.29143637418747\n",
            "7652 10000 46246 50000\n",
            "Epoch= 27  Train Accuracy= 92.492 , Test Accuracy= 76.52  Epoch loss= 120.69601115584373\n",
            "7597 10000 46133 50000\n",
            "Epoch= 28  Train Accuracy= 92.266 , Test Accuracy= 75.97  Epoch loss= 118.42888139933348\n",
            "7586 10000 46619 50000\n",
            "Epoch= 29  Train Accuracy= 93.238 , Test Accuracy= 75.86  Epoch loss= 114.18535594642162\n",
            "7569 10000 46050 50000\n",
            "Epoch= 30  Train Accuracy= 92.1 , Test Accuracy= 75.69  Epoch loss= 109.54055680334568\n",
            "7565 10000 46452 50000\n",
            "Epoch= 31  Train Accuracy= 92.904 , Test Accuracy= 75.65  Epoch loss= 104.13629674166441\n",
            "7587 10000 46709 50000\n",
            "Epoch= 32  Train Accuracy= 93.418 , Test Accuracy= 75.87  Epoch loss= 104.60958665981889\n",
            "7619 10000 47250 50000\n",
            "Epoch= 33  Train Accuracy= 94.5 , Test Accuracy= 76.19  Epoch loss= 100.34289797395468\n",
            "7582 10000 46428 50000\n",
            "Epoch= 34  Train Accuracy= 92.856 , Test Accuracy= 75.82  Epoch loss= 92.8152551651001\n",
            "7577 10000 47194 50000\n",
            "Epoch= 35  Train Accuracy= 94.388 , Test Accuracy= 75.77  Epoch loss= 92.90586123988032\n",
            "7501 10000 46241 50000\n",
            "Epoch= 36  Train Accuracy= 92.482 , Test Accuracy= 75.01  Epoch loss= 89.43267001211643\n",
            "7581 10000 47396 50000\n",
            "Epoch= 37  Train Accuracy= 94.792 , Test Accuracy= 75.81  Epoch loss= 93.29267702996731\n",
            "7635 10000 47842 50000\n",
            "Epoch= 38  Train Accuracy= 95.684 , Test Accuracy= 76.35  Epoch loss= 87.20003970339894\n",
            "7550 10000 47081 50000\n",
            "Epoch= 39  Train Accuracy= 94.162 , Test Accuracy= 75.5  Epoch loss= 79.66758452355862\n",
            "7539 10000 47289 50000\n",
            "Epoch= 40  Train Accuracy= 94.578 , Test Accuracy= 75.39  Epoch loss= 79.6166876219213\n",
            "7539 10000 47710 50000\n",
            "Epoch= 41  Train Accuracy= 95.42 , Test Accuracy= 75.39  Epoch loss= 80.80758482590318\n",
            "7592 10000 48045 50000\n",
            "Epoch= 42  Train Accuracy= 96.09 , Test Accuracy= 75.92  Epoch loss= 76.48293600603938\n",
            "7563 10000 48089 50000\n",
            "Epoch= 43  Train Accuracy= 96.178 , Test Accuracy= 75.63  Epoch loss= 71.57459060847759\n",
            "7559 10000 47842 50000\n",
            "Epoch= 44  Train Accuracy= 95.684 , Test Accuracy= 75.59  Epoch loss= 75.14428331330419\n",
            "7577 10000 47852 50000\n",
            "Epoch= 45  Train Accuracy= 95.704 , Test Accuracy= 75.77  Epoch loss= 71.7662416510284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-4bb061a0672a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnet2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m           \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0moptimizer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eADnZusIIv5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}